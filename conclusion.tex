\chapter*{Conclusion}\addcontentsline{toc}{chapter}{Conclusion}

In this dissertation, we study the population of exoplanets using data from
NASA's \kepler\ Mission and the re-purposed \KT\ Mission.
We develop and apply novel techniques to discover previously unknown planets
and planet candidates (\chapname s~\chapalt{ketu} and~\chapalt{peerless}).
We present a robust probabilistic framework for making inferences about the
population of exoplanets based on the noisy and incomplete catalogs derived
from transit surveys (\chap{exopop}).
The main contributions of this dissertation are methodological and each
\chapname\ is accompanied by open source software implementing the methods.

In the spirit of tool development and open source software, \Chap{emcee} is
describes \project{emcee}, a general purpose Markov Chain Monte Carlo sampler
that, since its release \citep{Foreman-Mackey:2013}, has become one of the
most popular tools for probabilistic inference in astronomy.
This method was originally proposed by \citet{Goodman:2010} and it was
designed to sample problems efficiently with little tuning even when the
parameter space is poorly conditioned.
This feature is especially useful for problems in astronomy where the physical
parameters often vary (and covary) over many orders of magnitude.
The \project{emcee} implementation offers a small performance gain by deriving
a parallelizable version of the original algorithm and a user-friendly and
well documented Python interface.
In practice, this method doesn't scale well to large numbers of dimensions
($\gtrsim 50$) but it has been shown to work out-of-the-box on a large class
of typical astronomy problems.

In \Chap{exopop}, we derive a hierarchical method for inferring the population
of exoplanets based on a catalog of planets with a non-trivial completeness
function and large measurement uncertainties.
This method builds on the importance sampling technique originally derived by
\citet{Hogg:2010a} to make a clean histogram from noisy measurements.
Applying this population inference method to a catalog of planet candidates
transiting Sun-like stars \citep{Petigura:2013}, we make a prediction for the
rate of Earth analogs.
This prediction is substantially lower than earlier predictions based on the
same catalog.
We demonstrate that this discrepancy is caused by both the treatment of the
observational uncertainties and the choice of extrapolation function.

In Summer 2014, the \kepler\ spacecraft was re-purposed and it began taking
data for the \KT\ Mission.
The pointing accuracy in this mode is substantially degraded relative to the
original Mission but, in \chap{ketu}, we demonstrate that these light curves
can still be used to systematically search for transiting exoplanets.
By building a flexible data-driven model for the systematic variability in the
light curves of the stars and combining this with an approximate linear
transit model, we derive a transit search algorithm where the systematics
model is marginalized for every hypothesis.
This enables the discovery of transit signals with amplitudes smaller than the
pointing-induced variability.
In \chap{ketu}, we announce the discovery of 36 planet candidates transiting
33 stars.
Of these candidates, 18 have been validated as bona fide planets and 6 have
been identified as likely astrophysical false positives
\citep{Crossfield:2015, Montet:2015, Armstrong:2015a}.

Finally, in \chap{peerless}, we present a novel method for detecting the
transits of planets with orbital periods longer than the baseline of
observations.
Existing transit search methods are blind to these long periods because it is
technically difficult to distinguish a single transit from coincidental
variability in light curves.
This constraint is not acceptable for forthcoming surveys like \KT\ and \tess\
where the observation baselines are shorter than the periods of the most
important planets for studies of dynamics and habitability.
We apply a supervised classification algorithm, implemented using a set of
Random Forest classifiers trained on simulated transits, to predict the
``class'' (\texttt{transit} or \texttt{no transit}) of every section of light
curve.
Using this method, we announce the discovery of a convincing single transit
candidate with a radius of $\sim 2\,R_\mathrm{J}$.

The ultimate goal of this research program is an improved understanding of the
population of exoplanets at the currently uncharted extremes of parameter
space, especially pushing to long periods.
This dissertation represents a step in this direction but there are some
conspicuously missing pieces in the methods presented in these pages.
One major shortcoming is that neither \chap{ketu} or \chap{peerless} realized
the dream of a fully automated search.
In both projects, a final stage of manual vetting was required to reach the
target precision.
This is unacceptable if we want to make rigorous inferences of the population
of planets because human components of a pipeline can't be stress-tested and
characterized for consistency and performance.
The main barrier to completely automated search is that we don't have an
acceptable generative model for the signals that are mis-classified by the
search algorithms and we can never be completely sure that any section of
light curve \emph{does not have any transits}.
This goal of fully automated transit discovery will become even more important
as new datasets continue to roll in from \KT, \tess, and \plato.
This should be a focus of large scale transit programs over the next years.










